package npairs;

import npairs.shared.matlib.*;
import extern.niftijlib.Nifti1Dataset;

import java.io.FileNotFoundException;
import java.io.IOException;
import java.io.PrintStream;

import npairs.utils.CVA;
import npairs.utils.PCA;
import npairs.utils.PredictionStats;
import npairs.utils.Resampler;
import npairs.io.NiftiIO;
import npairs.io.NpairsjIO;
import pls.shared.MLFuncs;
import npairs.utils.ZScorePatternInfo;
import npairs.io.NpairsDataLoader;

public class Npairsj  {
	
	boolean debug = false;
	/***************************************************************************************
	 * class Npairsj() // Main entry point for NPAIRS program
	 * @author anita oder
	 * 
	 **************************************************************************************/
	 
	NpairsjSetupParams setupParams; // Contains all param info entered by user.
	
	String matlibType;              // Which matrix library to use; current choices
	                                // are 'MATLAB' or 'COLT'(not case sensitive).
	
	int[][][] splits;               // Contains info about which split objects belong to each
	                                // split half when resampling data. Dims of 'splits' are 
	                                // [2][numSamples][]; splits[0] contains info for first split
	                                // half and splits[1] contains info for second split half, and 
	                                // numSamples = min(setupParams.numSplits, max poss splits).
	                                // Array elements are indices into setupParams.splitObjectLabels
	                                // array (in ascending order).
	                                //         
	
	NpairsDataLoader dataLoader;    // Contains Npairs data, feat-selected data and inverse feature-
	                                // selected data Matrices.
	
	/* Results: */
	
	Analysis fullDataAnalysis = null; // contains results from full-data analysis, if run 
	
	public CVA fullDataCVA;           // contains CVA results from full-data analysis, if run
	
	CVA splitDataCVA1;                // contains CVA results from first half split-data analysis, 
									  // if run (holds temp results from each split analysis as it's run)
	
	CVA splitDataCVA2;	              // contains CVA results from second half split-data analysis, 
	                                  // if run (holds temp results from each split analysis as it's run)
	
	public PCA fullDataPCA;           // contains PCA results from full-data analysis, if run
	
	PCA splitDataPCA1;                // contains PCA results from first half split-data analysis, 
									  // if run (holds temp results from each split analysis as it's run)
	
	PCA splitDataPCA2;	              // contains PCA results from second half split-data analysis, 
    								  // if run (holds temp results from each split analysis as it's run)
	
	Matrix split1CVAEvals;            // contains eigenvalues for each first split half (numSamples
	                                  // of them) and each CV dimension; dims = numSamples rows
    								  // X num CV dims cols
	
	Matrix split2CVAEvals;            // contains eigenvalues for each second split half (numSamples
    								  // of them) and each CV dimension; dims = numSamples rows
	                                  // X num CV dims cols
	
	public double[] avgSplit1CVAEvals; // contains avg CV evals across first split half CVA results;
	                                   // length of array = num CV dims
	public double[] avgSplit2CVAEvals; // contains avg CV evals across second split half CVA results;
	                                   // length of array = num CV dims
	 
	public Matrix avgCVScoresTrain;    // contains avg cv scores across all training sets;
	                                   // dims = num input data vols X num cv dims
	
	public Matrix avgCVScoresTest;     // contains avg cv scores across all test sets, i.e.,
	                                   // avg of cv scores generated by projecting test data onto
	                                   // corresponding training cv eigenimages;
	                                   // dims = num input data vols X num cv dims
	
	private Matrix[] r2;               // contains r^2 values calculated for each split half
	                                   // between CV scores and data input into CV (e.g. PC scores
	                                   // representing data in PC space)
	
	Matrix corrCoeffs;                 // contains correlation coefficients for each split 
    								   // between eigenimages from each split half analysis; 
    								   // dims are: numSamples rows (see 'splits' above) by
    								   // num dims in eigenimage results for model  
       								   // to be summarized (e.g. CV dims)
									   // (ONLY EXISTS if split 2 models are generated, i.e.,
	                                   // if training and test sets are switched.)

	Matrix noisePattStdDev;            // contains standard deviation of data from both split
                                       // halves projected onto 'noise' axis of scatterplot 
                                       // between split halves
                                       // dims are same as for corrCoeffs above
									   // (ONLY EXISTS if split 2 models are generated, i.e.,
    								   // if training and test sets are switched.)
	/* Prediction stats */
	
	// TODO: consider better storage strategy for prediction stats (ppAllClasses ordering of dims 
	//       inconsistent with rest of prediction variables; storing correctPred as array of double 
	//       Matrices is unwieldy)
	
	public Matrix[] ppTrueClass;       // for each test volume, contains posterior probabilities 
									   // (with and without priors)
	                                   // of belonging to true class 
	                                   // (1 Matrix for each split half)
	                                   // 1st row of each Matrix = probs with priors
	                                   // 2nd row "   "     "    = probs without priors
	
	public Matrix[] sqrdPredError;     // contains squared prediction error (1-ppTrueClass)^2
	                                   // (with and without priors)
    							       // for each test volume  
                                       // (1 Matrix for each split half)
                                       // 1st row of each Matrix = SPE with priors
                                       // 2nd row "   "     "    = SPE without priors
	
	public Matrix[] predClass;         // contains predicted class for each test volume
									   // (with and without priors)
									   // (1 Matrix for each split half)
									   // 1st row of each Matrix = probs with priors
									   // 2nd row "   "     "    = probs without priors
	
	public Matrix[] correctPred;       // contains labels for each test volume indicating 
	                                   // whether predicted class is true class: 
	                                   // 1.0 = true; 0.0 = false.
									   // (1 Matrix for each split half)
									   // 1st row of each Matrix = probs with priors
									   // 2nd row "   "     "    = probs without priors
	
	public Matrix[][] ppAllClasses;    // contains posterior probs (with and without priors)
	                                   // for each test volume of belonging to each class
	                                   // 	ppAllClasses[i][j] =  
	                                   // 	(no. test vols) X (no. classes) Matrix
	                                   // 	for j = 0 (priors) or 1 (no priors);
	                                   //   ith split half
/*	 Summary results:*/
	
	public Matrix avgSpatialPattern;  // contains spatial pattern average across all training
	                                  // datasets for analysis step that is to be 
									  // summarized (e.g. CVA results in PCA + CVA analysis, or 
									  // PCA results if only PCA run)
	                                  // No. of training sets: 2 * # splits in split-half X-validation;
	                                  //                           # input vols in bootstrap
	
	public Matrix avgZScorePattern;   // contains average rSPM(z) [normalized proj. of split 
	                                  // half patterns
		                              // onto 'signal axis'] across all splits for model  
	                                  // to be summarized
	                                  // (ONLY EXISTS if split 2 models are generated, i.e. if
	                                  // training and test sets are switched.)
	
	Matrix avgNoisePattern;	          // contains average noise pattern [normalized proj. of
	                                  // split half patterns onto 'noise axis'] across all
	                                  // splits for model to be summarized
									  // (ONLY EXISTS if split 2 models are generated, i.e. if
                                      // training and test sets are switched.)
	
	// TODO: calculate and save Npairsj.pattHistograms, Npairsj.zScorePattHistograms,
	//       Npairsj.summInfluence
	
	Matrix pattHistograms;          // contains histograms for spatial patterns generated
	                                // from each training set (only for analysis step that
	                                // is to be summarized)
	                                // ** will worry about details of generating this stat
	                                // later; implementation shown here will probably need
	                                // tweaking-- should be OK in terms of code structure, 
	                                // though **
	                                
	Matrix zScorePattHistograms;    // contains histograms for rSPM(z) patterns from each
	                                // training set (only for analysis step that is to be 
	                                // summarized)
	                                // ** will worry about details of generating this stat
	                                // later; implementation shown here will probably need
	                                // tweaking-- should be OK in terms of code structure, 
	                                // though **
	                                
	Matrix summInfluence;           // contains influence metrics for each Subject/Session
	                                // ** will worry about details of generating this stat
	                                // later ** (not implemented yet here)
	private boolean reshapedR2 = false; // set to true if r2 has been reshaped to final summary
	                                    // format (where there are nCVDims Matrices, each with
	                                    // dims nSplitAnalyses X no. data dims (e.g. PC dims) 
	                                    // input into CVA split analyses).
	public boolean computeR2 = true;  // always save r2 info (unless doing JavaQuadCVA)
	
	public static PrintStream output = System.out; // for directing all output statements 
	                                        // (to e.g. console or log file);
	                                        // initialized in NpairsjSetupParams.initLogFile()
	
	
	
	/**************************************************************************************/

	/***************************************************************************************
	 * Npairsj constructor takes either setup params .mat file or NpairsjSetupParams object:
	 * @param dataLoader
	 * @param paramMatFileName
	 * @param matlibType
	 * @param eventRelAnalysis 
	 * @throws NpairsjException
	 * @throws IOException 
	 **************************************************************************************/

	public Npairsj(NpairsDataLoader dataLoader, String paramMatFileName, String matlibType, 
			boolean eventRelAnalysis) throws NpairsjException, IOException {
		this(dataLoader, new NpairsjSetupParams(paramMatFileName, false),
				matlibType);
	}
	
	public Npairsj(NpairsDataLoader dataLoader, NpairsjSetupParams nsp, String matlibType) 
		throws NpairsjException, IOException {
		
		this.matlibType = matlibType;
		this.setupParams = nsp;
		this.dataLoader = dataLoader;
	//	this.computeR2 = nsp.saveLotsOfFiles;
		nsp.useQuadCVA = false; // Added by Grigori
		if (nsp.useQuadCVA) computeR2 = false; // not implemented for quad cva
		

		// TODO: fix saveListfile to work for updated NpairsjSetupParams dataFileNames and maskFileNames variables
//		if (setupParams.saveLotsOfFiles && setupParams.cvaRun) {
//			if (!setupParams.dataIs4D) {
//				try {
//					// save listfile (for IDL NPAIRS) 
//					// (needed to view cv scores plot using J. Anderson's idl tool
//					// 'cva_plot_cvs.pro')
//					setupParams.saveListfile();
//				}
//				catch (IOException e) {
//					throw new NpairsjException("Error saving listfile");
//				}
//			}
//		}
		
		double sTime = System.currentTimeMillis();
		
		// TODO: do preprocessing once here instead of every time an Analysis is run
//		if (setupParams.preProcess) {
//			if (setupParams.removeSessionMeans) {
//				 data = removeMeanSessionScans(setupParams.sessionLabels, data);
//			}
//		}
		
		runAnalysis();
		double tTime = (System.currentTimeMillis() - sTime) / 1000;

		int hr = (int)(tTime / 3600);
		int min = (int)((tTime / 60) - (hr * 60));
		double s = tTime - (hr * 3600) - (min * 60) ;
			output.print("Total time running NPAIRS analysis: " + hr + 
					" h " + min + " min ");
			output.printf("%.3f", s);
			output.println(" s");

	}

	private void runAnalysis() throws NpairsjException, IOException {

		// Full Data Analysis:
		if (setupParams.runFullDataAnalysis) {
			
			output.println("Running full-data analysis...");
			double sTime = System.currentTimeMillis();	
			
			runFullDataAnalysis();	
			
			double tTime = (System.currentTimeMillis() - sTime) / 1000;
			output.println("Finished running full data analysis [" + tTime + " s]");		
			
		}

		// Split Analyses and Stats Generation:

		if (setupParams.resampleData) {
//			 TODO: verify whether full-data reference analysis is really always
			// required when resampling data
			if (!setupParams.runFullDataAnalysis) {
				throw new NpairsjException("Must run full-data reference analysis " +
				"before resampling data");
			}
			
			createSplits(true);
			saveSplitVolInfo();

			output.println("Running split analyses...");
			double sTime = System.currentTimeMillis();	
			
			runSplitAnalyses();	
			
			double tTime = (System.currentTimeMillis() - sTime) / 1000;
			output.println("Finished running split analyses [" + tTime + " s]");		

			saveSummarySplitResults();
		}
	}
	

	private void saveSummarySplitResults() throws IOException, NpairsjException {
		// Always save true class post probs with priors in text file as 2D array.
		// If saveLotsOfFiles, save all summary prediction results in ASCII/Analyze format.
		output.println("Saving prediction stats...");
		savePredictionStats(setupParams.saveLotsOfFiles);
		
		// Always save reproducibility stats in a textfile, too.
		output.println("Saving reproducibility stats... ");
		saveCorrCoeffs("IDL");
		
		// And R2 output...
		output.println("Saving r2 values for each split analysis...");
		saveSummaryR2("IDL");
		
		if (setupParams.saveLotsOfFiles) {
			
			output.println("Saving average CV Scores (training and test)..." );
			saveAvgCVScores("IDL");

			output.println("Saving average spatial pattern... ");
			saveAvgSpatPattern("IDL");
			
//			if (computeR2) {
//				output.println("Saving r2 values for each split analysis...");
//				saveSummaryR2("IDL");
//			}
			
			if (setupParams.switchTrainAndTestSets) {

				output.println("Saving rSPM{Z}... ");
				saveZScoreAvgPatt("IDL");

				output.println("Saving average noise pattern... ");
				saveNoiseAvgPatt("IDL");

				output.println("Saving noise pattern stats... ");
				saveNoiseStdDev("IDL");
			}
		}
	}
	

	/** Saves summary r2 file across all splits for each CV Dim, not the individual 
	 *  r2 files that can be saved for each split analysis using CVA.saveCVAResultsIDL 
	 *  by setting boolean saveR2 input arg to true
	 * @param format
	 */
	private void saveSummaryR2(String format) throws NpairsjException {
		if (!reshapedR2) {
			throw new NpairsjException("Must reshape R2 Matrix array into summary " +
					"format before saving.");
		}
		if (format.toUpperCase().equals("IDL")) {		
				int nCVDims = r2.length;
				for (int cv = 0; cv < nCVDims; ++cv) {
					String r2SplitsFile = setupParams.resultsFilePrefix + ".CVA.SUMM.CVDIM_" 
						+ cv + ".r2";
					r2[cv].printToFile(r2SplitsFile, format);
				}
		}
		else {
			throw new  IllegalArgumentException("Output format \'" + format + "\' not "
					+ "implemented.");
		}	
	}

	private void runFullDataAnalysis() throws NpairsjException, IOException {
		if (setupParams.initFeatSelect) {
			fullDataAnalysis = new Analysis(dataLoader.getFeatSelData(), setupParams);
		} 
		else fullDataAnalysis = new Analysis(dataLoader.getOrigData(), setupParams);

		fullDataAnalysis.run();

		fullDataPCA = fullDataAnalysis.getPCA(); // null if pca not run	
		fullDataCVA = fullDataAnalysis.getCVA(); // null if cva not run

		if (setupParams.initFeatSelect) {
			// rotate results back to original space from 
			// initial feature selection space
			if (setupParams.pcaRun) {			
				if (setupParams.pcEigimsToBigSpace) {
					// TODO: replace cvaPCSetAll with generalized PC dims
					// (since if CVA not run, won't have cva PC set)	
					output.print("Transforming PCA back into orig. space... ");
					double sTime = System.currentTimeMillis();
					fullDataPCA.rotateEigimsToOrigSpace(setupParams.cvaPCSetAll,
							dataLoader.getEVDProjFactorMat(), dataLoader.getOrigData());
					double tTime = (System.currentTimeMillis() - sTime) / 1000;
					output.println("[" + tTime + " s]");

				}
			}
			if (setupParams.cvaRun) {
				double sTime = System.currentTimeMillis();
				if (debug) {
					output.print("Transforming CVA back into orig. space... ");
				}
				fullDataCVA.rotateEigimsToOrigSpace(dataLoader.getEVDProjFactorMat(), dataLoader.getOrigData());
				if (debug) {
					double tTime = (System.currentTimeMillis() - sTime) / 1000;
					output.println("[" + tTime + " s]");
				}
			}
		}
		saveFullDataResults();
	}
	

	private void saveFullDataResults() throws IOException, NpairsjException {
		if (setupParams.saveLotsOfFiles && setupParams.saveFullDataAnalysis) {
			if (setupParams.pcaRun) {
//				if (debug) {
					output.println("Saving full-data PCA results..."); 
//				}
				String pcaSavePref = setupParams.resultsFilePrefix;
				if (!setupParams.pcEigimsToBigSpace) {
					pcaSavePref += ".InitFSpace";
				}
				fullDataPCA.savePCAResultsIDL(pcaSavePref, null,
						false, 0, 0);
				
				
			}
			
			if (setupParams.cvaRun) {
//				if (debug) {
					output.println("Saving full-data CVA results...");
//				}
				fullDataCVA.saveCVAResultsIDL(setupParams.resultsFilePrefix, false, 0, 0, true);
			}
		}
		
		if (setupParams.saveDataPostPCA) {
			// save denoised (i.e. PCA dim-reduced) input data 
			// (in orig img space)
			output.print("Saving denoised (post-PCA) image data... ");
			double sTime = System.currentTimeMillis();
			if (!setupParams.pcEigimsToBigSpace) {
				// still need to project eigims into big space
				// before saving denoised data
				fullDataPCA.rotateEigimsToOrigSpace(setupParams.cvaPCSetAll,
					dataLoader.getEVDProjFactorMat(), dataLoader.getOrigData());
			}
			fullDataPCA.saveDataPostPCA(setupParams, dataLoader);
			double tTime = (System.currentTimeMillis() - sTime)/1000;
			output.println("[" + tTime + " s]");
		}
	}

	/** Runs split analyses and accumulates summary split results */
	
	private void runSplitAnalyses() throws NpairsjException, IOException {
		
		int numSamples = splits[0].length; // numSamples == min(setupParams.numSplits, max num splits)
		output.println("No. splits: " + numSamples);
		
		int totalNumSplitAnalyses = numSamples;
		if (setupParams.switchTrainAndTestSets) {
			totalNumSplitAnalyses = 2 * numSamples;
		}
		
		initPredStats(totalNumSplitAnalyses);
		if (computeR2) {
			initR2Results(totalNumSplitAnalyses);  
		}

		if (setupParams.cvaRun) {
			initCVASplitResults(numSamples);
		}

		int[] vCountTr = new int[setupParams.numVols]; 	// each element incremented whenever corresp.
														// vol (row of input data) incl. in sample 
        												// training data
		int[] vCountTe = new int[setupParams.numVols]; 	// each element incremented whenever corresp.
        												// vol incl. in sample test data
	
		int numAnalyses = 0;
		for (int splitNum = 0; splitNum < numSamples; ++splitNum) {

			Analysis firstPartAnalysis;
			Analysis secondPartAnalysis = null;

			int[] split1DataVols = splits[0][splitNum];
			int[] split2DataVols = splits[1][splitNum];
			if (setupParams.initFeatSelect) {
				firstPartAnalysis = 
					new Analysis(dataLoader.getFeatSelData(), setupParams, 
							split1DataVols, true, fullDataAnalysis);
				if (setupParams.switchTrainAndTestSets) {
					secondPartAnalysis = 
						new Analysis(dataLoader.getFeatSelData(), setupParams, 
								split2DataVols, false, fullDataAnalysis);
				}
			}
			else {
				firstPartAnalysis = 
					new Analysis(dataLoader.getOrigData(), setupParams, 
							split1DataVols, true, fullDataAnalysis);
				if (setupParams.switchTrainAndTestSets) {
					secondPartAnalysis =
						new Analysis(dataLoader.getOrigData(), setupParams, 
								split2DataVols, false, fullDataAnalysis);
				}
			}

			output.println("Split # 1/" 
					+ splitNum + ":");
			double sTime = System.currentTimeMillis();
			firstPartAnalysis.run();
			double tTime = (System.currentTimeMillis() - sTime) / 1000;
			output.println("Done split. [" + tTime + " s]");
			++numAnalyses;

			if (setupParams.switchTrainAndTestSets) {
				output.println("Split # 2/" 
						+ splitNum + ":");
				sTime = System.currentTimeMillis();
				secondPartAnalysis.run();
				tTime = (System.currentTimeMillis() - sTime) / 1000;
				output.println("Done split. [" + tTime + " s]");
				++numAnalyses;
			}
			
			if (setupParams.pcaRun) {
				splitDataPCA1 = firstPartAnalysis.getPCA(); 
				if (setupParams.switchTrainAndTestSets) {
					splitDataPCA2 = secondPartAnalysis.getPCA();
				}
			}
			
			splitDataCVA1 = firstPartAnalysis.getCVA();  // null if cva not run
			splitDataCVA2 = secondPartAnalysis.getCVA(); // null if cva not run or training and 
														 // test data not switched
			
			// Add r2 stats Matrix for current split half to r2 Matrix array.
			if (computeR2) {
				addCurrR2(splitNum);
			}

			Matrix split1CVSTrain = null;
			Matrix split1CVSTest = null;
			Matrix split2CVSTrain = null;
			Matrix split2CVSTest = null;
			if (setupParams.cvaRun) {
				//  Incorporate current split into summary CV-Training and CV-Test Scores				
				split1CVAEvals.setRow(splitNum, splitDataCVA1.getEvals());

				// Split1CVSTrain = 0 for vols not incl. in current split data
				split1CVSTrain = getTrainCVScores(splitDataCVA1, split1DataVols);
				
				for (int vol : split1DataVols) {
					vCountTr[vol] += 1;
				}

				avgCVScoresTrain = avgCVScoresTrain.plus(split1CVSTrain);

				// Project curr split test (split2) data onto curr split train (split1) 
				// CV eigenimages to get curr test CV scores. 

				// Split2CVSMatrix contains zeros in rows corresp. to vols not
				// incl. in curr test data 
				split2CVSTest = getTestCVScores(splitDataCVA1, split2DataVols);
						
				for (int vol : split2DataVols) {
					vCountTe[vol] += 1;
				}				
				avgCVScoresTest = avgCVScoresTest.plus(split2CVSTest);

				if (setupParams.switchTrainAndTestSets) {
					split2CVAEvals.setRow(splitNum, splitDataCVA2.getEvals());

					// Split2CVSTrain = 0 for vols not incl. in current split data
					split2CVSTrain = getTrainCVScores(splitDataCVA2, split2DataVols);

					for (int vol : split2DataVols) {
						vCountTr[vol] += 1;
					}

					avgCVScoresTrain = avgCVScoresTrain.plus(split2CVSTrain);
					// Project curr split test (split1) data onto curr split train (split2) 
					// CV eigenimages to get curr test CV scores. 

					// Split2CVSMatrix contains zeros in rows corresp. to vols not
					// incl. in curr test data 
					split1CVSTest = getTestCVScores(splitDataCVA2, split1DataVols);
					
					for (int vol : split1DataVols) {
						vCountTe[vol] += 1;
					}				
					avgCVScoresTest = avgCVScoresTest.plus(split1CVSTest);
				}
			}

			if (setupParams.initFeatSelect) {
				if (setupParams.cvaRun) {
					if (debug) {
						sTime = System.currentTimeMillis();
						output.print("Transforming split 1 CVA back into orig. space... ");
					}
					splitDataCVA1.rotateEigimsToOrigSpace(dataLoader.getEVDProjFactorMat(), 
							dataLoader.getOrigData());
					if (debug) {
						tTime = (System.currentTimeMillis() - sTime) / 1000;
						output.println("[" + tTime + " s]");
					}
				}

				if (setupParams.pcaRun) {
					if (setupParams.pcEigimsToBigSpace && setupParams.saveSplitDataResults) {
						// Project back into original data voxel space (large and time-consuming);
						// default is to stay in initial feature (e.g. svd) eigenimage space rather
						// than voxel space
						if (debug) {
							sTime = System.currentTimeMillis();
							output.print("Transforming split 1 PCA back into orig. space... ");
						}
						splitDataPCA1.rotateEigimsToOrigSpace(setupParams.cvaPCSet1, 
								dataLoader.getEVDProjFactorMat(), dataLoader.getOrigData());
						if (debug) {
							tTime = (System.currentTimeMillis() - sTime) / 1000;
							output.println("[" + tTime + " s]");
						}
					}
				}

				if (setupParams.switchTrainAndTestSets) {
					if (setupParams.cvaRun) {
						if (debug) {
							sTime = System.currentTimeMillis();
							output.print("Transforming split 2 CVA back into orig. space... ");
						}
						splitDataCVA2.rotateEigimsToOrigSpace(dataLoader.getEVDProjFactorMat(), 
								dataLoader.getOrigData());
						if (debug) {
							tTime = (System.currentTimeMillis() - sTime) / 1000;
							output.println("[" + tTime + " s]");
						}
					}

					if (setupParams.pcaRun) {
						if (setupParams.pcEigimsToBigSpace && setupParams.saveSplitDataResults) {
							if (debug) {
								sTime = System.currentTimeMillis();
								output.print("Transforming split 2 PCA back into orig. space... ");
							}
							splitDataPCA2.rotateEigimsToOrigSpace(setupParams.cvaPCSet2, 
									dataLoader.getEVDProjFactorMat(), dataLoader.getOrigData());
							if (debug) {
								tTime = (System.currentTimeMillis() - sTime) / 1000;
								output.print("[" + tTime + " s]");
							}
						}
					}
				}
			}

			//	Save split results in ASCII format:
			if (setupParams.saveSplitDataResults) {
				sTime = System.currentTimeMillis();
				output.print("Saving split results...");
				if (setupParams.pcaRun) {
					if (debug) {
						output.println("Saving 1st split half PCA results... ");
					}
					savePCASplitResults(splitNum, 1);
				}

				if (setupParams.cvaRun) {
					if (debug) {
						output.println("Saving 1st split half CVA results ");
					}
					splitDataCVA1.saveCVAResultsIDL(setupParams.resultsFilePrefix, 
							true, splitNum, 1, false);
				}

				if (setupParams.switchTrainAndTestSets) {
					if (setupParams.pcaRun) {
						if (debug) {
							output.println("Saving 2nd split half PCA results... ");
						}
						savePCASplitResults(splitNum, 2);
					}

					if (setupParams.cvaRun) {
						if (debug) {
							output.println("Saving 2nd split half CVA results ");
						}
						splitDataCVA2.saveCVAResultsIDL(setupParams.resultsFilePrefix, 
								true, splitNum, 2, false);
					}
				}
				tTime = (System.currentTimeMillis() - sTime) / 1000;
				output.println("[" + tTime + " s]");
			}

			// Incorporate current split data analysis pattern results into 
			// cumulative average results
			// TODO: clean up assumptions: currently, avg results only 
			// initialized and accumulated if setupParams.switchTrainAndTestSets == true,
			// and cva is assumed to have been run; but avgSpatialPattern should exist 
			// even if train and test sets are not switched.

			if (setupParams.switchTrainAndTestSets) {
				if (debug) {
					sTime = System.currentTimeMillis();
					output.print("Calculating Reproducibility stats... ");
				}
				ZScorePatternInfo zScorePattInfo = new ZScorePatternInfo(splitDataCVA1.getEigimsBig(), 
						splitDataCVA2.getEigimsBig());
				if (debug) {
					tTime = (System.currentTimeMillis() - sTime) / 1000;
					output.println("[" + tTime + " s]");
				}
				if (splitNum == 0) {
					avgSpatialPattern = splitDataCVA1.getEigimsBig();
					avgSpatialPattern = avgSpatialPattern.plus(splitDataCVA2.getEigimsBig());
					avgZScorePattern = zScorePattInfo.getSignalPattern();
					avgNoisePattern = zScorePattInfo.getNoisePattern();

					// must initialize noisePattStdDev and corrCoeffs 
					// because each col added one at a time
					noisePattStdDev = new MatrixImpl(numSamples, 
							avgNoisePattern.numCols()).getMatrix();
					corrCoeffs =  new MatrixImpl(numSamples, 
							avgNoisePattern.numCols()).getMatrix();
				}
				else {
					avgSpatialPattern = avgSpatialPattern.plus(
							splitDataCVA1.getEigimsBig());
					avgSpatialPattern = avgSpatialPattern.plus(
							splitDataCVA2.getEigimsBig());
					avgZScorePattern = avgZScorePattern.plus(
							zScorePattInfo.getSignalPattern());
					avgNoisePattern = avgNoisePattern.plus(
							zScorePattInfo.getNoisePattern());
				}
				noisePattStdDev.setRow(splitNum, zScorePattInfo.getNoiseStdDev());
				corrCoeffs.setRow(splitNum, zScorePattInfo.getCorrCoeffs());

				// TODO: lift the following if statement out of splitNum for loop
				if (splitNum == numSamples - 1) {
					avgSpatialPattern = avgSpatialPattern.mult(1.0 / (double)(numSamples * 2));			
					avgZScorePattern = avgZScorePattern.mult(1.0 / (double)numSamples);
					avgNoisePattern = avgNoisePattern.mult(1.0 / (double)numSamples);					
				} 		
			} // end if switch train/test 


			// Prediction metrics can be calculated whenever there is a test 
			// set (or equivalently in NPAIRS, whenever resampling is done)
			computePredStats(numAnalyses, split1DataVols, split2DataVols, 
					split1CVSTrain, split1CVSTest, split2CVSTrain, split2CVSTest);
			
		} // end for loop through splits
		
		
		// Finish calculating avg cv scores and evals:
		// divide avgCVScoresTrain/Test rows by corresponding vCounts.  
		// If vCount = 0, then corresponding row in avgCVScoresTrain/Test 
		// will be all zeros.
		for (int r = 0; r < setupParams.numVols; ++r) {
			if (vCountTr[r] > 0) {
				double[] avgCVSTrCurrRow = 
					MLFuncs.divide(avgCVScoresTrain.getRowQuick(r), (double)vCountTr[r]);
				avgCVScoresTrain.setRowQuick(r, avgCVSTrCurrRow);
			}
			if (vCountTe[r] > 0) {
				double[] avgCVSTestCurrRow = 
					MLFuncs.divide(avgCVScoresTest.getRowQuick(r), (double)vCountTe[r]);
				avgCVScoresTest.setRowQuick(r, avgCVSTestCurrRow);
			}
		}

		avgSplit1CVAEvals = split1CVAEvals.colMeans();
		if (setupParams.switchTrainAndTestSets) {
			avgSplit2CVAEvals = split2CVAEvals.colMeans();
		}		

		// Reshape r2 data.  Currently have a Matrix (nPCDims X nCVDims) for 
		// each split analysis; want a Matrix (nSplitAnalyses X nPCDims) for 
		// each CV Dim.
		if (computeR2) {
			r2 = reshapeR2();
		}
		// Pad prediction stats with -1's so all Matrices have maxNTestVols columns
		padPredStats(totalNumSplitAnalyses);	

	}
	
	/** Rearranges r2 data from an array of (numSplitAnalyses) Matrices with
	 *  dims (nPCDims rows X nCVDims cols) to an array of (nCVDims) Matrices 
	 *  with dims (nSplitAnalyses rows X nPCDims cols).
	 * @return rearranged array of r2 Matrices
	 */
	private Matrix[] reshapeR2() {
		int nAnalyses = r2.length;
		int nPCDims = r2[0].numRows();
		int nCVDims = r2[0].numCols();
		Matrix[] r2PerCVDim = new Matrix[nCVDims];
		for (int cv = 0; cv < nCVDims; ++cv) {
			r2PerCVDim[cv] = new MatrixImpl(nAnalyses, nPCDims).getMatrix();
			for (int i = 0; i < nAnalyses; ++i) {
				r2PerCVDim[cv].setRow(i, r2[i].getColumn(cv));
			}
		}
		reshapedR2 = true;
		return r2PerCVDim;
	}

	/** Adds current split r2 stats to r2 Matrix 
	 * @param splitNum - (0-relative) number of current data split
	 * 
	 */
	private void addCurrR2(int splitNum) {
		int analysisNum = splitNum;
		if (setupParams.switchTrainAndTestSets) {
			analysisNum *= 2;
		}
		if (setupParams.cvaRun) {
			r2[analysisNum] = splitDataCVA1.getR2();
			if (setupParams.switchTrainAndTestSets) {
				r2[analysisNum + 1] = splitDataCVA2.getR2();
			}	
		}	
	}

	private void initR2Results(int totalNumSplitAnalyses) {
		r2 = new Matrix[totalNumSplitAnalyses];
	}

	private void initCVASplitResults(int numSamples) {
		// TODO: if split1,split2 have diff. number of pcs, the following
		// code will have to change
		int nCVDimsSplit1 = setupParams.cvaPCSet1.length;
		int nCVDims = Math.min(fullDataCVA.getNumCVDims(), nCVDimsSplit1);
		split1CVAEvals = new MatrixImpl(numSamples, nCVDims).getMatrix();
		avgSplit1CVAEvals = new double[nCVDims];
		avgCVScoresTrain = new MatrixImpl(setupParams.numVols, nCVDims).getMatrix();
		avgCVScoresTest = new MatrixImpl(setupParams.numVols, nCVDims).getMatrix();

		if (setupParams.switchTrainAndTestSets) {

			split2CVAEvals = new MatrixImpl(numSamples, nCVDims).getMatrix();
			avgSplit2CVAEvals = new double[nCVDims];
		}		
	}

	private void initPredStats(int totalNoSplitAnalyses) {
		ppTrueClass = new Matrix[totalNoSplitAnalyses];
		sqrdPredError = new Matrix[totalNoSplitAnalyses];
		predClass = new Matrix[totalNoSplitAnalyses];
		correctPred = new Matrix[totalNoSplitAnalyses];
		ppAllClasses = new Matrix[totalNoSplitAnalyses][2];
	}

	/** Determine samples for each split.  
	  * @param random
	  * 	If true, create uniformly random split samples (unless
	  *     no. of samples to be created is >= 90% of total
	  *     possible no. of samples; in this case, samples
	  *     are created deterministically even if 'random' is
	  *     set to 'true').
	  *     If false, create split samples deterministically.
	  * @see Resampler
	  */
	private void createSplits(boolean random) throws NpairsjException {

		if (setupParams.splits == null) {
			double sTime = System.currentTimeMillis();
			Resampler res = new Resampler(setupParams.getSplitObjLabels(), 
					setupParams.getGroupLabels(), setupParams.numSplitObjInSplits, 
					setupParams.numSplits);

			// 'splits' is array with dims [2][numSamples][] where 
			// numSamples == min(numSplits, max poss splits)
			splits = res.generateSplits(random);
			if (debug) {
				double tTime = (System.currentTimeMillis() - sTime) / 1000;
				output.println("Total time creating splits: " + tTime + " s");
			}
		} 
		else {
			splits = setupParams.splits;
		}
	}

	private void padPredStats(int totalNumAnalyses) {
		int maxNTestVols = 0;
		for (int i = 0; i < totalNumAnalyses; ++i) {
			maxNTestVols = Math.max(maxNTestVols,ppTrueClass[i].numCols());
		}

		for (int j = 0; j < totalNumAnalyses; ++j) {
			if (ppTrueClass[j].numCols() < maxNTestVols) {
				Matrix tmpPP = new MatrixImpl(2, maxNTestVols).getMatrix();
				tmpPP.set(-1);
				tmpPP.setSubMatrix(ppTrueClass[j], 0, 0);
				ppTrueClass[j] = tmpPP;

				Matrix tmpSPE = new MatrixImpl(2, maxNTestVols).getMatrix();
				tmpSPE.set(-1);
				tmpSPE.setSubMatrix(sqrdPredError[j], 0, 0);
				sqrdPredError[j] = tmpSPE;

				Matrix tmpPredCls = new MatrixImpl(2, maxNTestVols).getMatrix();
				tmpPredCls.set(-1);
				tmpPredCls.setSubMatrix(predClass[j], 0, 0);
				predClass[j] = tmpPredCls;

				Matrix tmpCorrPred = new MatrixImpl(2, maxNTestVols).getMatrix();
				tmpCorrPred.set(-1);
				tmpCorrPred.setSubMatrix(correctPred[j], 0, 0);
				correctPred[j] = tmpCorrPred;

				int nModelDims = ppAllClasses[0][0].numCols();
				Matrix tmpPPAll = new MatrixImpl(maxNTestVols, nModelDims).getMatrix();
				tmpPPAll.set(-1);
				tmpPPAll.setSubMatrix(ppAllClasses[j][0], 0, 0);
				ppAllClasses[j][0] = tmpPPAll;
				Matrix tmpPPAllNoP = new MatrixImpl(maxNTestVols, nModelDims).getMatrix();
				tmpPPAllNoP.set(-1);
				tmpPPAllNoP.setSubMatrix(ppAllClasses[j][1], 0, 0);
				ppAllClasses[j][1] = tmpPPAllNoP;			
			}	
		}
	}

	private void computePredStats(int numAnalyses, 
								int[] split1DataVols, 
								int[] split2DataVols, 
								Matrix split1CVSTrain, 
								Matrix split1CVSTest, 
								Matrix split2CVSTrain, 
								Matrix split2CVSTest) throws NpairsjException {
		double sTime = 0;
		double tTime = 0;
		if (debug) {
			output.print("Calculating Prediction Stats "
					+ "for 1st split half... ");
			sTime = System.currentTimeMillis();
		}
		PredictionStats predStats1 = new PredictionStats(split1CVSTrain, split2CVSTest,
				split1DataVols, split2DataVols, setupParams.getClassLabels());
		if (debug) {
			tTime = (System.currentTimeMillis() - sTime) / 1000;
			output.println("[" + tTime + "]");
		}

		// add to cumulative prediction stats
		int currAnalysis = numAnalyses;
		if (setupParams.switchTrainAndTestSets) {
			currAnalysis--;  // numAnalyses was incremented twice but curr 
			// analysis is for first train set
		}
		ppTrueClass[currAnalysis - 1] = new MatrixImpl(predStats1.
				getPPTrueClass()).getMatrix();
		sqrdPredError[currAnalysis - 1] = new MatrixImpl(predStats1.
				getSqrdPredError()).getMatrix();
		predClass[currAnalysis - 1] = new MatrixImpl(predStats1.
				getPredClass()).getMatrix();
		correctPred[currAnalysis - 1] = new MatrixImpl(predStats1.
				getCorrectPred()).getMatrix();
		ppAllClasses[currAnalysis - 1][0] = new MatrixImpl(predStats1.
				getPPAllClasses(0)).getMatrix();
		ppAllClasses[currAnalysis - 1][1] = new MatrixImpl(predStats1.
				getPPAllClasses(1)).getMatrix();

		PredictionStats predStats2 = null;
		if (setupParams.switchTrainAndTestSets) {
			currAnalysis++; // was decremented for first train set
			if (debug) {
				output.print("Calculating Prediction Stats "
						+ "for 2nd split half... ");
				sTime = System.currentTimeMillis();
			}
			predStats2 = new PredictionStats(split2CVSTrain, split1CVSTest,
					split2DataVols, split1DataVols, setupParams.getClassLabels());			
			if (debug) {
				tTime = (System.currentTimeMillis() - sTime) / 1000;
				output.println("[" + tTime + "]");
			}

			ppTrueClass[currAnalysis - 1] = new MatrixImpl(predStats2.
					getPPTrueClass()).getMatrix();
			sqrdPredError[currAnalysis - 1] = new MatrixImpl(predStats2.
					getSqrdPredError()).getMatrix();
			predClass[currAnalysis - 1] = new MatrixImpl(predStats2.
					getPredClass()).getMatrix();
			correctPred[currAnalysis - 1] = new MatrixImpl(predStats2.
					getCorrectPred()).getMatrix();
			ppAllClasses[currAnalysis - 1][0] = new MatrixImpl(predStats2.
					getPPAllClasses(0)).getMatrix();
			ppAllClasses[currAnalysis - 1][1] = new MatrixImpl(predStats2.
					getPPAllClasses(1)).getMatrix();
		}
	}
	

	
	
	private void savePredictionStats(boolean saveLotsOfFiles) throws IOException {
	
		// Matrix[totalNumAnalyses] ppTrueClass
		//         "                sqrdPredError
		//         "                predClass                                            
        //         "                correctPred
	    // Matrix[totalNumAnalyses][2] ppAllClasses
		//  - each Matrix is 2 X num test vols except
		//    for ppAllClasses Matrices, which are
		//    num test vols X num classes
		
		int nAnalyses = ppTrueClass.length;
		int maxNTestVols = 0;  // not all test sets have same number of vols
		for (int i = 0; i < nAnalyses; ++i) {
			maxNTestVols = Math.max(maxNTestVols, ppTrueClass[i].numCols());
		}
		// always save true class post probs with priors for all split halves and test vols
		// in text file as 2D array, even if not saving lots of files
		Matrix ppTrueClsPriors = new MatrixImpl(nAnalyses, maxNTestVols).getMatrix();
		for (int i = 0; i < nAnalyses; ++i) {
			ppTrueClsPriors.setRow(i, ppTrueClass[i].getRow(0));
		}
		String modelType = "";
		if (setupParams.cvaRun) {
			modelType = "CVA";
		}
		String ppTruePriorsFilename = setupParams.resultsFilePrefix + "." + modelType + 
			".SUMM.PP.ppTruePriors";
		ppTrueClsPriors.printToFile(ppTruePriorsFilename, "IDL");
		
		if (saveLotsOfFiles) {	// save all the prediction stats, not just the true class post probs

			int nModelDims = ppAllClasses[0][0].numCols();
			double[][][] ppTrueCls3D = new double[nAnalyses][2][maxNTestVols];
			double[][][] sqrdPredErr3D = new double[nAnalyses][2][maxNTestVols];
			double[][][] predCls3D = new double[nAnalyses][2][maxNTestVols];
			double[][][] corrPred3D = new double[nAnalyses][2][maxNTestVols];
			double[][][] ppAllClsPriors3D = new double[nAnalyses][maxNTestVols][nModelDims]; 
			double[][][] ppAllClsNoPriors3D = new double[nAnalyses][maxNTestVols][nModelDims]; 

			for (int i = 0; i < nAnalyses; ++i) {
				ppTrueCls3D[i] = ppTrueClass[i].toArray();
				sqrdPredErr3D[i] = sqrdPredError[i].toArray();
				predCls3D[i] = predClass[i].toArray();
				corrPred3D[i] = correctPred[i].toArray();
				ppAllClsPriors3D[i] = ppAllClasses[i][0].toArray();
				ppAllClsNoPriors3D[i] = ppAllClasses[i][1].toArray();
			}

			// save in .img/hdr 3D volume format 
			String ppTrueFilename = setupParams.resultsFilePrefix + "." + modelType + ".SUMM.PP.pp";
			String speFilename = setupParams.resultsFilePrefix + "." + modelType + ".SUMM.PP.spe";
			String predClsFilename = setupParams.resultsFilePrefix + "." + modelType + ".SUMM.PP.predCls";
			String corrPFilename = setupParams.resultsFilePrefix + "." + modelType + ".SUMM.PP.pred";
			String ppAllPriorsFilename = setupParams.resultsFilePrefix + "." + modelType + ".SUMM.PP.ppAllPriors";
			String ppAllNoPriorsFilename = setupParams.resultsFilePrefix + "." + modelType + ".SUMM.PP.ppAllNoPriors";

			// TODO: consider xyz ordering in these volumes (although they're not images, we still
			// need to understand how the data is ordered in the file)
			int datatype = 16; // 32-bit float
			NiftiIO.writeVol(ppTrueCls3D, datatype, ppTrueFilename);
			NiftiIO.writeVol(sqrdPredErr3D, datatype, speFilename);
			NiftiIO.writeVol(predCls3D, datatype, predClsFilename);
			NiftiIO.writeVol(corrPred3D, datatype, corrPFilename);
			NiftiIO.writeVol(ppAllClsPriors3D, datatype, ppAllPriorsFilename);
			NiftiIO.writeVol(ppAllClsNoPriors3D, datatype, ppAllNoPriorsFilename);

//			if (debug) {
//				ppTrueClass[0].transpose().printToFile(setupParams.resultsFilePrefix 
//						+ ".CVA.SUMM.PP.0", "IDL");
//				sqrdPredError[0].transpose().printToFile(setupParams.resultsFilePrefix
//						+ ".CVA.SUMM.spe.0", "IDL");
//			}
		}		
	}

	public NpairsjSetupParams getSetupParams() {
		return setupParams;
	}		
	
	public Matrix getCorrCoeffs() {
		return corrCoeffs;
	}
	
//	public static void writeVol(double[][][] vol3D, String filename) throws IOException, FileNotFoundException {
//		Nifti1Dataset niftiDS = new Nifti1Dataset();
//		niftiDS.setHeaderFilename(filename);
//		niftiDS.setDataFilename(filename);
//		niftiDS.setDatatype((short)64);
//		niftiDS.setDims((short)3, (short)vol3D[0][0].length, (short)vol3D[0].length, (short)vol3D.length, 
//				(short)0, (short)0, (short)0, (short)0);
//		niftiDS.writeHeader();
//		niftiDS.writeVol(vol3D, (short)0);
//	}
	
	
	/***************************************************************************************
	 * Private helper methods:
	 ***************************************************************************************
	*/	
	
	/** Returns new Matrix containing test CV scores, i.e., cvaTest data
	 *  projected onto cvaTrain CVA eigenimages, for vols in test data set.
	 *  Vols not incl. in test data set have cv scores set to zero in 
	 *  returned Matrix.
	 *  Dim CVA eigenimages -  numDataCols (nVox, nFeatSelDims or nPCDimsForCVA) X nCVDims
	 *  Dim testData - numTestDataVols X numDataCols
	 *  
	 *   @param cvaTrain - cva of training data 
	 *   @param testDataVols - indices of vols (rows) of test data in full data set 
	 */ 
	private Matrix getTestCVScores(CVA cvaTrain, int[] testDataVols) {
		Matrix testData = null;	

		if (setupParams.initFeatSelect) {
			testData = dataLoader.getFeatSelData().subMatrixRows(testDataVols);
		}
		else {
			testData = dataLoader.getOrigData().subMatrixRows(testDataVols);
		}
		testData = testData.meanCentreColumns();
		
		Matrix cvsTest = cvaTrain.calcTestCVScores(testData);
		Matrix cvsTestPadded = cvsTest.zeroPadRows(setupParams.numVols, testDataVols);
		return cvsTestPadded;
	}
	
	
	/** Returns new Matrix containing training CV scores.
	 *  Vols not incl. in training data set have cv scores set to zero in 
	 *  returned Matrix.
	 *  Dim CVA eigenimages -  numDataCols (nVox or nFeatSelDims) X nCVDims
	 *  Dim trainingData - numTrainDataVols X numDataCols
	 *  
	 *   @param cvaTrain - cva of training data 
	 *   @param trainDataVols - indices of vols (rows) of training data in 
	 *                          full data set 
	 */  
	private Matrix getTrainCVScores(CVA cvaTrain, int[] trainDataVols) {
		Matrix cvsTr = cvaTrain.getCVScores();
		Matrix cvsTrPadded = cvsTr.zeroPadRows(setupParams.numVols, trainDataVols);
		return cvsTrPadded;
	}
	
	public Matrix[] getR2() {
		return r2;
	}
	
	private void saveSplitVolInfo() throws IOException {
		// Save splits vol info into single read_matrix.pro-format file
		// (compatible with IDL npairs SETUP .vols file)
		// NOTE that volume indices are 1-RELATIVE in IDL-compatible file
		int numSamples = splits[0].length;
		//reorder 'splits' so first row == first split half sample 1,
		//                   second row == 2nd split half sample 1,
		//                    third row == first split half sample 2,
		//                   fourth row == 2nd split half sample 2,
		//                              ... etc. 
		//  store result in tmpSplits
		// NOTE that if split halves containing less than max no. of vols
		// across all split halves will be zero-padded so all rows have same
		// no. of elements
		int[][] tmpSplits = new int[2 * numSamples][];
		int maxNumVols = 0;
		for (int s = 0; s < numSamples; ++s) {
			int currMax = Math.max(splits[0][s].length, splits[1][s].length);
			maxNumVols = Math.max(maxNumVols, currMax);
		}
		for (int s = 0; s < numSamples; ++s) {
			
			int[] zeropadSplits0 = new int[maxNumVols];
			for (int i = 0; i < splits[0][s].length; ++i) {
				zeropadSplits0[i] = splits[0][s][i] + 1;
			}
			for (int j = splits[0][s].length; j < maxNumVols; ++j) {
				zeropadSplits0[j] = 0;
			}
			int[] zeropadSplits1 = new int[maxNumVols];
			for (int i = 0; i < splits[1][s].length; ++i) {
				zeropadSplits1[i] = splits[1][s][i] + 1;
			}
			for (int j = splits[1][s].length; j < maxNumVols; ++j) {
				zeropadSplits1[j] = 0;
			}

			tmpSplits[2 * s] = zeropadSplits0;
			tmpSplits[2 * s + 1] = zeropadSplits1;
		}

		String splitsInfoSaveFilename = setupParams.resultsFilePrefix + ".vols";
		NpairsjIO.printToIDLFile(tmpSplits, splitsInfoSaveFilename);
	}
	
	
	private void saveAvgSpatPattern(String format) {
		if (format.toUpperCase().equals("IDL")) {
			String avgSpatPattFilename = setupParams.resultsFilePrefix + ".CVA.SUMM.AVG.eigim";
			avgSpatialPattern.printToFile(avgSpatPattFilename, format);
		}
		else {
			throw new IllegalArgumentException("Input format \'" + format + "\' not "
					+ "implemented.");
		}
	}
	
	
	private void saveZScoreAvgPatt(String format) {
		if (format.toUpperCase().equals("IDL")) {
			String avgZScorePattFilename = setupParams.resultsFilePrefix + ".CVA.SUMM.AVG.rSPM-Z";
			avgZScorePattern.printToFile(avgZScorePattFilename, format);
		}
		else {
			throw new  IllegalArgumentException("Input format \'" + format + "\' not "
					+ "implemented.");
		}
	}
	
	
	private void saveNoiseAvgPatt(String format) {
		if (format.toUpperCase().equals("IDL")) {
			String avgNoisePattFilename = setupParams.resultsFilePrefix + ".CVA.SUMM.AVG.noise";
			avgNoisePattern.printToFile(avgNoisePattFilename, format);
		}
		else {
			throw new  IllegalArgumentException("Input format \'" + format + "\' not "
					+ "implemented.");
		}
	}
	
	
	private void saveNoiseStdDev(String format) {
		if (format.toUpperCase().equals("IDL")) {
			String noiseStdDevFilename = setupParams.resultsFilePrefix + ".CVA.SUMM.noise-sd";
			noisePattStdDev.printToFile(noiseStdDevFilename, format);
		}
		else {
			throw new  IllegalArgumentException("Input format \'" + format + "\' not "
					+ "implemented.");
		}
	}
	
	
	private void saveCorrCoeffs(String format) {
		if (format.toUpperCase().equals("IDL")) { 
			String corrCoeffsFilename = setupParams.resultsFilePrefix + ".CVA.SUMM.CC";
			corrCoeffs.printToFile(corrCoeffsFilename, format);
		}
		else {
			throw new  IllegalArgumentException("Input format \'" + format + "\' not "
					+ "implemented.");
		}
	}
	
	private void saveAvgCVScores(String format) {
		if (format.toUpperCase().equals("IDL")) {
			String saveCVSTrain = setupParams.resultsFilePrefix + ".CVA.SUMM.AVG.CV-TR";
			avgCVScoresTrain.printToFile(saveCVSTrain, format);
			String saveCVSTest = setupParams.resultsFilePrefix + ".CVA.SUMM.AVG.CV-TE";
			avgCVScoresTest.printToFile(saveCVSTest, format);
		}
		else {
			throw new  IllegalArgumentException("Input format \'" + format + "\' not "
					+ "implemented.");
		}
	}
	
	
	/** Save PCA results for current split half 'splitNo'.
	 *  (Split numbers are 1-relative: 1, 2) 
	 */
	private void savePCASplitResults(int splitNum, int splitHalf) throws NpairsjException { 

		String pcaSavePref = setupParams.resultsFilePrefix;
		if (!setupParams.pcEigimsToBigSpace) {
			pcaSavePref += ".InitFSpace";
		}
		if (splitHalf == 1) {
			splitDataPCA1.savePCAResultsIDL(pcaSavePref, null, true,
					splitNum, splitHalf);
			// save denoised (i.e. PCA dim-reduced) input data 
			// (in orig img space) 
			// TODO: determine if one would ever want split image
			// data saved (doesn't seem likely)
//			if (setupParams.saveDataPostPCA) {
//				splitDataPCA1.saveDataPostPCA(dataLoader);
//			}
		}
		else {
			splitDataPCA2.savePCAResultsIDL(pcaSavePref, null, true,
					splitNum, splitHalf);
			// save denoised (i.e. PCA dim-reduced) input data 
			// (in orig img space)
//			if (setupParams.saveDataPostPCA) {
//				splitDataPCA2.saveDataPostPCA(dataLoader);
//			}
		}
	}
	
//	/**Only rotates the input pca eigenimage dimensions back into original space; otherwise would take
//	 * prohibitive length of time for large data.  
//	 * NOTE: pca pc scores and eigenvalues are also truncated to include only input pca dims.
//	 * @param pca
//	 * @param pcaDims
//	 * @param invProjectedData TODO
//	 * @param origData TODO
//	 */
//	private void rotateEigimsToOrigSpace(PCA pca, int[] pcaDims, Matrix invProjectedData, Matrix origData) {
//
//		// project pca eigenimages back onto inverted feature-selection 
//		// projection Matrix, i.e., feat-sel eigenimages (note that inverted
//		// proj. matrix == transpose of proj. matrix == Vt)
//
//		// P = MV ==> PVt = M ==> Vt = (invP)M == inverted feat-sel
//		// 	proj. Matrix (Vt), i.e. feat-sel eigims == transpose of proj. Matrix V.
//		// Vt ( == invSVDEigims, e.g.,) == too large to store, hence
//		// store invP = invFeatSelData instead to reconstruct Vt on the fly.
//		// Vt = (invP)M ==> PVt = P(invP)M ==> P1Vt = P1(invP)M = M1
//		// where P1 = PCA eigenimages in rows, in this case, and M1 = 
//		// PCA eigims in rows proj. back into orig. voxel space.
//		// given size P1 is reducDataDims X reducDataDims 
//		// and size (invP) is reducDataDims X data.numRows(),
//		// and size M is data.numRows() X origDataDims,
//		// want M1t = origDataDims X reducDataDims();
//		// TODO: Want to retain only significant dimensions of PCs! 
//		// (see IDL code for comparison)
//
//		// size P1(invP) is reducDataDims X data.numRows(): 	
////		Matrix P1invP = pca.getEvects(pcaDims).transpose().mult(dataLoader.getInvFeatSelData());
//		Matrix P1invP = pca.getEvects(pcaDims).transpose().mult(invProjectedData);
//
//		// instead of multiplying P1 by invPM 
//		// == (reducDataDims X reducDataDims) * (reducDataDims X origDataDims),
//		// multiply P1(invP) by M
//		// == (reducDataDims X data.numRows()) * (data.numRows() X origDataDims)
//		// == fewer calculations
////		Matrix voxSpacePCAEvects = P1invP.mult(dataLoader.getOrigData());
//		Matrix voxSpacePCAEvects = P1invP.mult(origData);
//		
//		pca.setEvects(voxSpacePCAEvects.transpose());
//		pca.truncateEvalsAndScores(pcaDims);
//		
//	}
	
//	private void rotateEigimsToOrigSpace(CVA cva, Matrix invProjectedData, Matrix origData) {
//		// project cva results back onto inverted feature-selection 
//		// projection Matrix
//		// (see PCA.rotateEigimsToOrigSpace(...) documentation for algebraic details)
//		
////		double sTime = System.currentTimeMillis();
//		Matrix P1invP = cva.getEigims().transpose().mult(invProjectedData);
////		if (debug) {
////			double tTime = (System.currentTimeMillis() - sTime) / (double)1000;
////			output.println("Total time calc. A = cvEigim*iFeatSelData (rot): " + tTime  + " s");
////			output.println("Dims A: " + P1invP.numRows() + " X " + P1invP.numCols());
////		}
////		sTime = System.currentTimeMillis();
//		Matrix voxSpaceCVAEigims = P1invP.mult(origData);
////		if (debug) {
////			double tTime = (System.currentTimeMillis() - sTime) / (double)1000;
////			output.println("Total time calc. A*origData: " + tTime + " s");
////		}
//		cva.setEigims(voxSpaceCVAEigims.transpose());
//		
//	}
	
	
	public boolean useCondsAsClasses() {
		return setupParams.useCondsAsClasses;
	}

	public NpairsDataLoader getDataLoader() {
		return dataLoader;
	}

//	public void finalize() throws Throwable {
//		System.out.println("Npairsj killed.");
//		
//		super.finalize();
//	}
}
